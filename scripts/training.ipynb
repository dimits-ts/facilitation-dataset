{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "MAX_LENGTH = 2048\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = transformers.LongformerForSequenceClassification.from_pretrained(\n",
    "    \"allenai/longformer-base-4096\",\n",
    ")\n",
    "tokenizer = transformers.LongformerTokenizerFast.from_pretrained(\n",
    "    \"allenai/longformer-base-4096\", max_length=MAX_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, train_percent=0.6, validate_percent=0.2, seed=None):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../pefk.csv\")\n",
    "df = df[df.dataset.isin([\"wikidisputes\", \"wikitactics\"])]\n",
    "df = df.reset_index()\n",
    "df.is_moderator = df.is_moderator.astype(int)\n",
    "train_df, val_df, test_df = train_validate_test_split(\n",
    "    df, train_percent=0.7, validate_percent=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_contextual_dataset(df, context_window=3):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "\n",
    "    # Group by conversation\n",
    "    for conv_id, group in df.groupby(\"conv_id\"):\n",
    "        texts = group[\"text\"].tolist()\n",
    "        users = group[\"user\"].tolist()\n",
    "        labels = group[\"is_moderator\"].tolist()\n",
    "\n",
    "        for i in range(len(texts)):\n",
    "            # Get previous `context_window` comments\n",
    "            start = max(0, i - context_window)\n",
    "            context = [\n",
    "                f\"<TURN> User {users[j]} posted: {texts[j]}\" for j in range(start, i)\n",
    "            ]\n",
    "\n",
    "            current = f\"<TURN> User {users[i]} posted: {texts[i]}\"\n",
    "\n",
    "            # Combine context and current\n",
    "            input_text = \" \".join(context + [current])\n",
    "            inputs.append(input_text)\n",
    "            outputs.append(labels[i])\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "\n",
    "X_train, y_train = build_contextual_dataset(train_df, context_window=2)\n",
    "X_val, y_val = build_contextual_dataset(val_df, context_window=2)\n",
    "X_test, y_test = build_contextual_dataset(test_df, context_window=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3a9f26d3654549b7085fc7435a196a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/72356 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ff8c291a35403bbe62b43524d1d441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15505 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "def torch_dataset(x, y):\n",
    "    dataset = Dataset.from_dict({\"text\": x, \"label\": y})\n",
    "    dataset = dataset.map(tokenize_function, batched=True)\n",
    "    dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,  # For Longformer models\n",
    "    )\n",
    "\n",
    "\n",
    "# Create a Hugging Face dataset from your training data\n",
    "train_dataset = torch_dataset(X_train, y_train)\n",
    "val_dataset = torch_dataset(X_val, y_val)\n",
    "test_dataset = torch_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing global attention on CLS token...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='21708' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   26/21708 01:25 < 21:34:41, 0.28 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1508' max='3101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1508/3101 14:45 < 15:35, 1.70 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     29\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m: accuracy_score(labels, preds),\n\u001b[32m     30\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m\"\u001b[39m: f1_score(labels, preds),\n\u001b[32m     31\u001b[39m     }\n\u001b[32m     34\u001b[39m trainer = Trainer(\n\u001b[32m     35\u001b[39m     model=model,\n\u001b[32m     36\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m     compute_metrics=compute_metrics,\n\u001b[32m     40\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m trainer.train()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/transformers/trainer.py:2240\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2238\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[32m   2241\u001b[39m         args=args,\n\u001b[32m   2242\u001b[39m         resume_from_checkpoint=resume_from_checkpoint,\n\u001b[32m   2243\u001b[39m         trial=trial,\n\u001b[32m   2244\u001b[39m         ignore_keys_for_eval=ignore_keys_for_eval,\n\u001b[32m   2245\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/transformers/trainer.py:2622\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2620\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.epoch = epoch + (step + \u001b[32m1\u001b[39m + steps_skipped) / steps_in_epoch\n\u001b[32m   2621\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_step_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2622\u001b[39m     \u001b[38;5;28mself\u001b[39m._maybe_log_save_evaluate(\n\u001b[32m   2623\u001b[39m         tr_loss,\n\u001b[32m   2624\u001b[39m         grad_norm,\n\u001b[32m   2625\u001b[39m         model,\n\u001b[32m   2626\u001b[39m         trial,\n\u001b[32m   2627\u001b[39m         epoch,\n\u001b[32m   2628\u001b[39m         ignore_keys_for_eval,\n\u001b[32m   2629\u001b[39m         start_time,\n\u001b[32m   2630\u001b[39m         learning_rate=learning_rate,\n\u001b[32m   2631\u001b[39m     )\n\u001b[32m   2632\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2633\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_substep_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/transformers/trainer.py:3095\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[39m\n\u001b[32m   3093\u001b[39m metrics = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3094\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.control.should_evaluate:\n\u001b[32m-> \u001b[39m\u001b[32m3095\u001b[39m     metrics = \u001b[38;5;28mself\u001b[39m._evaluate(trial, ignore_keys_for_eval)\n\u001b[32m   3096\u001b[39m     is_new_best_metric = \u001b[38;5;28mself\u001b[39m._determine_best_metric(metrics=metrics, trial=trial)\n\u001b[32m   3098\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_strategy == SaveStrategy.BEST:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/transformers/trainer.py:3044\u001b[39m, in \u001b[36mTrainer._evaluate\u001b[39m\u001b[34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[39m\n\u001b[32m   3043\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m3044\u001b[39m     metrics = \u001b[38;5;28mself\u001b[39m.evaluate(ignore_keys=ignore_keys_for_eval)\n\u001b[32m   3045\u001b[39m     \u001b[38;5;28mself\u001b[39m._report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m.state.global_step, metrics)\n\u001b[32m   3047\u001b[39m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/transformers/trainer.py:4173\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4170\u001b[39m start_time = time.time()\n\u001b[32m   4172\u001b[39m eval_loop = \u001b[38;5;28mself\u001b[39m.prediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluation_loop\n\u001b[32m-> \u001b[39m\u001b[32m4173\u001b[39m output = eval_loop(\n\u001b[32m   4174\u001b[39m     eval_dataloader,\n\u001b[32m   4175\u001b[39m     description=\u001b[33m\"\u001b[39m\u001b[33mEvaluation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   4176\u001b[39m     \u001b[38;5;66;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;00m\n\u001b[32m   4177\u001b[39m     \u001b[38;5;66;03m# self.args.prediction_loss_only\u001b[39;00m\n\u001b[32m   4178\u001b[39m     prediction_loss_only=\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   4179\u001b[39m     ignore_keys=ignore_keys,\n\u001b[32m   4180\u001b[39m     metric_key_prefix=metric_key_prefix,\n\u001b[32m   4181\u001b[39m )\n\u001b[32m   4183\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n\u001b[32m   4184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_jit_compilation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/transformers/trainer.py:4368\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4365\u001b[39m         batch_size = observed_batch_size\n\u001b[32m   4367\u001b[39m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4368\u001b[39m losses, logits, labels = \u001b[38;5;28mself\u001b[39m.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)\n\u001b[32m   4369\u001b[39m main_input_name = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmain_input_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4370\u001b[39m inputs_decode = (\n\u001b[32m   4371\u001b[39m     \u001b[38;5;28mself\u001b[39m._prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args.include_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4372\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/transformers/trainer.py:4584\u001b[39m, in \u001b[36mTrainer.prediction_step\u001b[39m\u001b[34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[39m\n\u001b[32m   4582\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[32m   4583\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4584\u001b[39m         loss, outputs = \u001b[38;5;28mself\u001b[39m.compute_loss(model, inputs, return_outputs=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   4585\u001b[39m     loss = loss.detach().mean()\n\u001b[32m   4587\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/transformers/trainer.py:3810\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3808\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3809\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3810\u001b[39m outputs = model(**inputs)\n\u001b[32m   3811\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3812\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:1835\u001b[39m, in \u001b[36mLongformerForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, global_attention_mask, head_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1832\u001b[39m     \u001b[38;5;66;03m# global attention on cls token\u001b[39;00m\n\u001b[32m   1833\u001b[39m     global_attention_mask[:, \u001b[32m0\u001b[39m] = \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1835\u001b[39m outputs = \u001b[38;5;28mself\u001b[39m.longformer(\n\u001b[32m   1836\u001b[39m     input_ids,\n\u001b[32m   1837\u001b[39m     attention_mask=attention_mask,\n\u001b[32m   1838\u001b[39m     global_attention_mask=global_attention_mask,\n\u001b[32m   1839\u001b[39m     head_mask=head_mask,\n\u001b[32m   1840\u001b[39m     token_type_ids=token_type_ids,\n\u001b[32m   1841\u001b[39m     position_ids=position_ids,\n\u001b[32m   1842\u001b[39m     inputs_embeds=inputs_embeds,\n\u001b[32m   1843\u001b[39m     output_attentions=output_attentions,\n\u001b[32m   1844\u001b[39m     output_hidden_states=output_hidden_states,\n\u001b[32m   1845\u001b[39m     return_dict=return_dict,\n\u001b[32m   1846\u001b[39m )\n\u001b[32m   1847\u001b[39m sequence_output = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1848\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.classifier(sequence_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:1640\u001b[39m, in \u001b[36mLongformerModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, global_attention_mask, head_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1632\u001b[39m extended_attention_mask: torch.Tensor = \u001b[38;5;28mself\u001b[39m.get_extended_attention_mask(attention_mask, input_shape)[\n\u001b[32m   1633\u001b[39m     :, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, :\n\u001b[32m   1634\u001b[39m ]\n\u001b[32m   1636\u001b[39m embedding_output = \u001b[38;5;28mself\u001b[39m.embeddings(\n\u001b[32m   1637\u001b[39m     input_ids=input_ids, position_ids=position_ids, token_type_ids=token_type_ids, inputs_embeds=inputs_embeds\n\u001b[32m   1638\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1640\u001b[39m encoder_outputs = \u001b[38;5;28mself\u001b[39m.encoder(\n\u001b[32m   1641\u001b[39m     embedding_output,\n\u001b[32m   1642\u001b[39m     attention_mask=extended_attention_mask,\n\u001b[32m   1643\u001b[39m     head_mask=head_mask,\n\u001b[32m   1644\u001b[39m     padding_len=padding_len,\n\u001b[32m   1645\u001b[39m     output_attentions=output_attentions,\n\u001b[32m   1646\u001b[39m     output_hidden_states=output_hidden_states,\n\u001b[32m   1647\u001b[39m     return_dict=return_dict,\n\u001b[32m   1648\u001b[39m )\n\u001b[32m   1649\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1650\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:1299\u001b[39m, in \u001b[36mLongformerEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, padding_len, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1288\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m   1289\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m   1290\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1296\u001b[39m         output_attentions,\n\u001b[32m   1297\u001b[39m     )\n\u001b[32m   1298\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1299\u001b[39m     layer_outputs = layer_module(\n\u001b[32m   1300\u001b[39m         hidden_states,\n\u001b[32m   1301\u001b[39m         attention_mask=attention_mask,\n\u001b[32m   1302\u001b[39m         layer_head_mask=head_mask[idx] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1303\u001b[39m         is_index_masked=is_index_masked,\n\u001b[32m   1304\u001b[39m         is_index_global_attn=is_index_global_attn,\n\u001b[32m   1305\u001b[39m         is_global_attn=is_global_attn,\n\u001b[32m   1306\u001b[39m         output_attentions=output_attentions,\n\u001b[32m   1307\u001b[39m     )\n\u001b[32m   1308\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1310\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[32m   1311\u001b[39m     \u001b[38;5;66;03m# bzs x seq_len x num_attn_heads x (num_global_attn + attention_window_len + 1) => bzs x num_attn_heads x seq_len x (num_global_attn + attention_window_len + 1)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:1227\u001b[39m, in \u001b[36mLongformerLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[39m\n\u001b[32m   1217\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   1218\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1219\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1225\u001b[39m     output_attentions=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1226\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1227\u001b[39m     self_attn_outputs = \u001b[38;5;28mself\u001b[39m.attention(\n\u001b[32m   1228\u001b[39m         hidden_states,\n\u001b[32m   1229\u001b[39m         attention_mask=attention_mask,\n\u001b[32m   1230\u001b[39m         layer_head_mask=layer_head_mask,\n\u001b[32m   1231\u001b[39m         is_index_masked=is_index_masked,\n\u001b[32m   1232\u001b[39m         is_index_global_attn=is_index_global_attn,\n\u001b[32m   1233\u001b[39m         is_global_attn=is_global_attn,\n\u001b[32m   1234\u001b[39m         output_attentions=output_attentions,\n\u001b[32m   1235\u001b[39m     )\n\u001b[32m   1236\u001b[39m     attn_output = self_attn_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1237\u001b[39m     outputs = self_attn_outputs[\u001b[32m1\u001b[39m:]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:1163\u001b[39m, in \u001b[36mLongformerAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[39m\n\u001b[32m   1153\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   1154\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1155\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1161\u001b[39m     output_attentions=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1162\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1163\u001b[39m     self_outputs = \u001b[38;5;28mself\u001b[39m.self(\n\u001b[32m   1164\u001b[39m         hidden_states,\n\u001b[32m   1165\u001b[39m         attention_mask=attention_mask,\n\u001b[32m   1166\u001b[39m         layer_head_mask=layer_head_mask,\n\u001b[32m   1167\u001b[39m         is_index_masked=is_index_masked,\n\u001b[32m   1168\u001b[39m         is_index_global_attn=is_index_global_attn,\n\u001b[32m   1169\u001b[39m         is_global_attn=is_global_attn,\n\u001b[32m   1170\u001b[39m         output_attentions=output_attentions,\n\u001b[32m   1171\u001b[39m     )\n\u001b[32m   1172\u001b[39m     attn_output = \u001b[38;5;28mself\u001b[39m.output(self_outputs[\u001b[32m0\u001b[39m], hidden_states)\n\u001b[32m   1173\u001b[39m     outputs = (attn_output,) + self_outputs[\u001b[32m1\u001b[39m:]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:589\u001b[39m, in \u001b[36mLongformerSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;66;03m# compute local attention probs from global attention keys and contact over window dim\u001b[39;00m\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_global_attn:\n\u001b[32m    583\u001b[39m     \u001b[38;5;66;03m# compute global attn indices required through out forward fn\u001b[39;00m\n\u001b[32m    584\u001b[39m     (\n\u001b[32m    585\u001b[39m         max_num_global_attn_indices,\n\u001b[32m    586\u001b[39m         is_index_global_attn_nonzero,\n\u001b[32m    587\u001b[39m         is_local_index_global_attn_nonzero,\n\u001b[32m    588\u001b[39m         is_local_index_no_global_attn_nonzero,\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m     ) = \u001b[38;5;28mself\u001b[39m._get_global_attn_indices(is_index_global_attn)\n\u001b[32m    590\u001b[39m     \u001b[38;5;66;03m# calculate global attn probs from global key\u001b[39;00m\n\u001b[32m    592\u001b[39m     global_key_attn_scores = \u001b[38;5;28mself\u001b[39m._concat_with_global_key_attn_probs(\n\u001b[32m    593\u001b[39m         query_vectors=query_vectors,\n\u001b[32m    594\u001b[39m         key_vectors=key_vectors,\n\u001b[32m   (...)\u001b[39m\u001b[32m    598\u001b[39m         is_local_index_no_global_attn_nonzero=is_local_index_no_global_attn_nonzero,\n\u001b[32m    599\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/SSD_4TB_2/dtsirmpas/software/miniforge/envs/pefk-dataset/lib/python3.12/site-packages/transformers/models/longformer/modeling_longformer.py:919\u001b[39m, in \u001b[36mLongformerSelfAttention._get_global_attn_indices\u001b[39m\u001b[34m(is_index_global_attn)\u001b[39m\n\u001b[32m    916\u001b[39m max_num_global_attn_indices = num_global_attn_indices.max()\n\u001b[32m    918\u001b[39m \u001b[38;5;66;03m# indices of global attn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m is_index_global_attn_nonzero = is_index_global_attn.nonzero(as_tuple=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    921\u001b[39m \u001b[38;5;66;03m# helper variable\u001b[39;00m\n\u001b[32m    922\u001b[39m is_local_index_global_attn = torch.arange(\n\u001b[32m    923\u001b[39m     max_num_global_attn_indices, device=is_index_global_attn.device\n\u001b[32m    924\u001b[39m ) < num_global_attn_indices.unsqueeze(dim=-\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "GRAD_ACC_STEPS = 2\n",
    "EVAL_STEPS = 200\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../results/training\",\n",
    "    per_device_train_batch_size=5,\n",
    "    per_device_eval_batch_size=5,\n",
    "    num_train_epochs=3,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=EVAL_STEPS / GRAD_ACC_STEPS,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=EVAL_STEPS / GRAD_ACC_STEPS,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_dir=\"../logs\",\n",
    "    logging_steps=EVAL_STEPS / GRAD_ACC_STEPS,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    gradient_accumulation_steps=GRAD_ACC_STEPS,\n",
    ")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=1)  # numpy operation\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds),\n",
    "    }\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "print(results)\n",
    "\n",
    "trainer.save_model(\"./best_model\")  # Save the best model\n",
    "tokenizer.save_pretrained(\"./best_model\")  # Also save the tokenizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pefk-dataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
